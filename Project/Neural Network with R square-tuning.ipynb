{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"E:/weka/Dataset/Real estate valuation data set.xlsx\")\n",
    "df = pd.DataFrame(df)\n",
    "df = df.drop(['No'],axis=1)\n",
    "df = np.array(df)\n",
    "splitted_array = np.split(df,[-1],axis=1)\n",
    "data = pd.DataFrame(splitted_array[0])\n",
    "label = pd.DataFrame(splitted_array[1])\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing dataset into training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 56        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,417\n",
      "Trainable params: 1,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\18202\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Epoch 1/300\n",
      "310/310 [==============================] - 3s 11ms/step - loss: 1655.3881\n",
      "Epoch 2/300\n",
      "310/310 [==============================] - 0s 145us/step - loss: 1646.7483\n",
      "Epoch 3/300\n",
      "310/310 [==============================] - 0s 132us/step - loss: 1637.0769\n",
      "Epoch 4/300\n",
      "310/310 [==============================] - 0s 142us/step - loss: 1620.7799\n",
      "Epoch 5/300\n",
      "310/310 [==============================] - 0s 125us/step - loss: 1595.8839\n",
      "Epoch 6/300\n",
      "310/310 [==============================] - 0s 142us/step - loss: 1554.5189\n",
      "Epoch 7/300\n",
      "310/310 [==============================] - 0s 151us/step - loss: 1484.7827\n",
      "Epoch 8/300\n",
      "310/310 [==============================] - 0s 171us/step - loss: 1373.6934\n",
      "Epoch 9/300\n",
      "310/310 [==============================] - 0s 116us/step - loss: 1209.4974\n",
      "Epoch 10/300\n",
      "310/310 [==============================] - 0s 113us/step - loss: 984.4740\n",
      "Epoch 11/300\n",
      "310/310 [==============================] - 0s 122us/step - loss: 701.7850\n",
      "Epoch 12/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 418.4315\n",
      "Epoch 13/300\n",
      "310/310 [==============================] - 0s 113us/step - loss: 220.3512\n",
      "Epoch 14/300\n",
      "310/310 [==============================] - 0s 113us/step - loss: 154.4643\n",
      "Epoch 15/300\n",
      "310/310 [==============================] - 0s 116us/step - loss: 151.4731\n",
      "Epoch 16/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 146.6882\n",
      "Epoch 17/300\n",
      "310/310 [==============================] - 0s 113us/step - loss: 143.3918\n",
      "Epoch 18/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 140.0679\n",
      "Epoch 19/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 137.0972\n",
      "Epoch 20/300\n",
      "310/310 [==============================] - 0s 119us/step - loss: 134.9523\n",
      "Epoch 21/300\n",
      "310/310 [==============================] - 0s 109us/step - loss: 132.4996\n",
      "Epoch 22/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 130.3802\n",
      "Epoch 23/300\n",
      "310/310 [==============================] - 0s 113us/step - loss: 127.1765\n",
      "Epoch 24/300\n",
      "310/310 [==============================] - 0s 113us/step - loss: 123.9971\n",
      "Epoch 25/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 120.0892\n",
      "Epoch 26/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 116.1135\n",
      "Epoch 27/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 112.0061\n",
      "Epoch 28/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 108.8575\n",
      "Epoch 29/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 106.3074\n",
      "Epoch 30/300\n",
      "310/310 [==============================] - 0s 129us/step - loss: 103.9076\n",
      "Epoch 31/300\n",
      "310/310 [==============================] - 0s 125us/step - loss: 101.9265\n",
      "Epoch 32/300\n",
      "310/310 [==============================] - 0s 113us/step - loss: 99.6357\n",
      "Epoch 33/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 97.9228\n",
      "Epoch 34/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 97.2190\n",
      "Epoch 35/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 94.8624\n",
      "Epoch 36/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 93.9879\n",
      "Epoch 37/300\n",
      "310/310 [==============================] - 0s 109us/step - loss: 92.8244\n",
      "Epoch 38/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 91.8285\n",
      "Epoch 39/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 90.4645\n",
      "Epoch 40/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 89.1741\n",
      "Epoch 41/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 88.8762\n",
      "Epoch 42/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 87.4291\n",
      "Epoch 43/300\n",
      "310/310 [==============================] - 0s 119us/step - loss: 86.2579\n",
      "Epoch 44/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 85.5223\n",
      "Epoch 45/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 84.8077\n",
      "Epoch 46/300\n",
      "310/310 [==============================] - 0s 87us/step - loss: 83.8061\n",
      "Epoch 47/300\n",
      "310/310 [==============================] - 0s 77us/step - loss: 83.5188\n",
      "Epoch 48/300\n",
      "310/310 [==============================] - 0s 77us/step - loss: 82.6821\n",
      "Epoch 49/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 82.1796\n",
      "Epoch 50/300\n",
      "310/310 [==============================] - 0s 80us/step - loss: 82.2603\n",
      "Epoch 51/300\n",
      "310/310 [==============================] - 0s 84us/step - loss: 81.1365\n",
      "Epoch 52/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 80.5519\n",
      "Epoch 53/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 80.4888\n",
      "Epoch 54/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 79.4605\n",
      "Epoch 55/300\n",
      "310/310 [==============================] - 0s 80us/step - loss: 80.0609\n",
      "Epoch 56/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 79.6751\n",
      "Epoch 57/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 78.8478\n",
      "Epoch 58/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 77.9662\n",
      "Epoch 59/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 77.8783\n",
      "Epoch 60/300\n",
      "310/310 [==============================] - 0s 116us/step - loss: 77.1970\n",
      "Epoch 61/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 77.2962\n",
      "Epoch 62/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 76.9262\n",
      "Epoch 63/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 76.2076\n",
      "Epoch 64/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 75.9472\n",
      "Epoch 65/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 75.4464\n",
      "Epoch 66/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 76.1680\n",
      "Epoch 67/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 75.4217\n",
      "Epoch 68/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 75.7407\n",
      "Epoch 69/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - 0s 119us/step - loss: 74.6131\n",
      "Epoch 70/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 74.9735\n",
      "Epoch 71/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 74.2168\n",
      "Epoch 72/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 73.7385\n",
      "Epoch 73/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 73.4052\n",
      "Epoch 74/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 73.2746\n",
      "Epoch 75/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 73.6361\n",
      "Epoch 76/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 72.7529\n",
      "Epoch 77/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 72.3769\n",
      "Epoch 78/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 73.2258\n",
      "Epoch 79/300\n",
      "310/310 [==============================] - 0s 122us/step - loss: 73.5109\n",
      "Epoch 80/300\n",
      "310/310 [==============================] - 0s 119us/step - loss: 72.2914\n",
      "Epoch 81/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 72.4352\n",
      "Epoch 82/300\n",
      "310/310 [==============================] - 0s 122us/step - loss: 72.2907\n",
      "Epoch 83/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 72.9497\n",
      "Epoch 84/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 72.7038\n",
      "Epoch 85/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 71.8552\n",
      "Epoch 86/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 71.1737\n",
      "Epoch 87/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 71.2679\n",
      "Epoch 88/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 70.5822\n",
      "Epoch 89/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 70.6676\n",
      "Epoch 90/300\n",
      "310/310 [==============================] - 0s 109us/step - loss: 71.0631\n",
      "Epoch 91/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 70.7224\n",
      "Epoch 92/300\n",
      "310/310 [==============================] - 0s 113us/step - loss: 71.8179\n",
      "Epoch 93/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 70.4587\n",
      "Epoch 94/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 70.3676\n",
      "Epoch 95/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 70.1512\n",
      "Epoch 96/300\n",
      "310/310 [==============================] - 0s 116us/step - loss: 70.6949\n",
      "Epoch 97/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 69.6040\n",
      "Epoch 98/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 70.2380\n",
      "Epoch 99/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 69.2677\n",
      "Epoch 100/300\n",
      "310/310 [==============================] - 0s 87us/step - loss: 69.5366\n",
      "Epoch 101/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 70.2157\n",
      "Epoch 102/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 68.9078\n",
      "Epoch 103/300\n",
      "310/310 [==============================] - 0s 77us/step - loss: 69.8286\n",
      "Epoch 104/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 69.2412\n",
      "Epoch 105/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 68.6650\n",
      "Epoch 106/300\n",
      "310/310 [==============================] - 0s 87us/step - loss: 69.2178\n",
      "Epoch 107/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 68.9502\n",
      "Epoch 108/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 68.5159\n",
      "Epoch 109/300\n",
      "310/310 [==============================] - 0s 119us/step - loss: 69.4967\n",
      "Epoch 110/300\n",
      "310/310 [==============================] - 0s 109us/step - loss: 68.0397\n",
      "Epoch 111/300\n",
      "310/310 [==============================] - 0s 87us/step - loss: 68.0585\n",
      "Epoch 112/300\n",
      "310/310 [==============================] - 0s 135us/step - loss: 68.1044\n",
      "Epoch 113/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 68.0797\n",
      "Epoch 114/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 68.5588\n",
      "Epoch 115/300\n",
      "310/310 [==============================] - 0s 87us/step - loss: 68.1287\n",
      "Epoch 116/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 68.0998\n",
      "Epoch 117/300\n",
      "310/310 [==============================] - 0s 74us/step - loss: 67.7683\n",
      "Epoch 118/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 67.8381\n",
      "Epoch 119/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 67.4232\n",
      "Epoch 120/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 67.5178\n",
      "Epoch 121/300\n",
      "310/310 [==============================] - 0s 87us/step - loss: 67.0088\n",
      "Epoch 122/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 67.6354\n",
      "Epoch 123/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 67.2871\n",
      "Epoch 124/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 66.8425\n",
      "Epoch 125/300\n",
      "310/310 [==============================] - 0s 87us/step - loss: 67.1361\n",
      "Epoch 126/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 67.0287\n",
      "Epoch 127/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 66.9156\n",
      "Epoch 128/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 68.1069\n",
      "Epoch 129/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 67.4766\n",
      "Epoch 130/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 68.0531\n",
      "Epoch 131/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 66.6806\n",
      "Epoch 132/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 67.0713\n",
      "Epoch 133/300\n",
      "310/310 [==============================] - 0s 87us/step - loss: 68.0926\n",
      "Epoch 134/300\n",
      "310/310 [==============================] - 0s 84us/step - loss: 66.4251\n",
      "Epoch 135/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 66.4675\n",
      "Epoch 136/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 66.0987\n",
      "Epoch 137/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 67.0688\n",
      "Epoch 138/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 66.3626\n",
      "Epoch 139/300\n",
      "310/310 [==============================] - 0s 87us/step - loss: 66.1335\n",
      "Epoch 140/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 65.7804\n",
      "Epoch 141/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 65.9875\n",
      "Epoch 142/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 67.6947\n",
      "Epoch 143/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 65.9184\n",
      "Epoch 144/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 66.2113\n",
      "Epoch 145/300\n",
      "310/310 [==============================] - 0s 87us/step - loss: 66.3373\n",
      "Epoch 146/300\n",
      "310/310 [==============================] - 0s 87us/step - loss: 66.7804\n",
      "Epoch 147/300\n",
      "310/310 [==============================] - 0s 80us/step - loss: 65.5217\n",
      "Epoch 148/300\n",
      "310/310 [==============================] - 0s 84us/step - loss: 66.2371\n",
      "Epoch 149/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 65.3825\n",
      "Epoch 150/300\n",
      "310/310 [==============================] - ETA: 0s - loss: 75.48 - 0s 106us/step - loss: 67.5190\n",
      "Epoch 151/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 68.0714\n",
      "Epoch 152/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 65.4621\n",
      "Epoch 153/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 65.9994\n",
      "Epoch 154/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 65.1960\n",
      "Epoch 155/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 64.7562\n",
      "Epoch 156/300\n",
      "310/310 [==============================] - 0s 84us/step - loss: 65.8084\n",
      "Epoch 157/300\n",
      "310/310 [==============================] - 0s 87us/step - loss: 65.2666\n",
      "Epoch 158/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 65.0721\n",
      "Epoch 159/300\n",
      "310/310 [==============================] - 0s 116us/step - loss: 65.0021\n",
      "Epoch 160/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 65.7191\n",
      "Epoch 161/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 64.6979\n",
      "Epoch 162/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 65.0917\n",
      "Epoch 163/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 66.0594\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - 0s 103us/step - loss: 64.3513\n",
      "Epoch 165/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 64.8630\n",
      "Epoch 166/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 64.7171\n",
      "Epoch 167/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 65.4758\n",
      "Epoch 168/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 64.3869\n",
      "Epoch 169/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 65.5499\n",
      "Epoch 170/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 66.0612\n",
      "Epoch 171/300\n",
      "310/310 [==============================] - 0s 80us/step - loss: 64.2108\n",
      "Epoch 172/300\n",
      "310/310 [==============================] - 0s 84us/step - loss: 64.0680\n",
      "Epoch 173/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 64.0189\n",
      "Epoch 174/300\n",
      "310/310 [==============================] - 0s 80us/step - loss: 64.2927\n",
      "Epoch 175/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 64.1573\n",
      "Epoch 176/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 63.9075\n",
      "Epoch 177/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 64.4849\n",
      "Epoch 178/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 64.0684\n",
      "Epoch 179/300\n",
      "310/310 [==============================] - 0s 80us/step - loss: 63.8258\n",
      "Epoch 180/300\n",
      "310/310 [==============================] - 0s 87us/step - loss: 64.1083\n",
      "Epoch 181/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 64.7862\n",
      "Epoch 182/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 64.2132\n",
      "Epoch 183/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 64.9198\n",
      "Epoch 184/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 63.3884\n",
      "Epoch 185/300\n",
      "310/310 [==============================] - 0s 80us/step - loss: 63.0341\n",
      "Epoch 186/300\n",
      "310/310 [==============================] - 0s 87us/step - loss: 63.3607\n",
      "Epoch 187/300\n",
      "310/310 [==============================] - 0s 80us/step - loss: 63.6197\n",
      "Epoch 188/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 64.9121\n",
      "Epoch 189/300\n",
      "310/310 [==============================] - 0s 84us/step - loss: 63.6112\n",
      "Epoch 190/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 62.7869\n",
      "Epoch 191/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 64.7641\n",
      "Epoch 192/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 63.3506\n",
      "Epoch 193/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 63.0475\n",
      "Epoch 194/300\n",
      "310/310 [==============================] - 0s 109us/step - loss: 63.2197\n",
      "Epoch 195/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 63.0396\n",
      "Epoch 196/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 62.6892\n",
      "Epoch 197/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 62.5931\n",
      "Epoch 198/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 62.7953\n",
      "Epoch 199/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 62.4892\n",
      "Epoch 200/300\n",
      "310/310 [==============================] - 0s 87us/step - loss: 62.8004\n",
      "Epoch 201/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 63.4504\n",
      "Epoch 202/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 63.4635\n",
      "Epoch 203/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 62.9809\n",
      "Epoch 204/300\n",
      "310/310 [==============================] - 0s 113us/step - loss: 63.1554\n",
      "Epoch 205/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 62.2155\n",
      "Epoch 206/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 62.9730\n",
      "Epoch 207/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 62.4928\n",
      "Epoch 208/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 63.0554\n",
      "Epoch 209/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 62.6906\n",
      "Epoch 210/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 62.3165\n",
      "Epoch 211/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 63.8989\n",
      "Epoch 212/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 63.5422\n",
      "Epoch 213/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 63.1817\n",
      "Epoch 214/300\n",
      "310/310 [==============================] - 0s 87us/step - loss: 61.9692\n",
      "Epoch 215/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 62.6671\n",
      "Epoch 216/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 62.7986\n",
      "Epoch 217/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 63.7291\n",
      "Epoch 218/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 62.9836\n",
      "Epoch 219/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 64.1025\n",
      "Epoch 220/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 62.2639\n",
      "Epoch 221/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 62.5559\n",
      "Epoch 222/300\n",
      "310/310 [==============================] - 0s 80us/step - loss: 63.2971\n",
      "Epoch 223/300\n",
      "310/310 [==============================] - 0s 84us/step - loss: 62.6420\n",
      "Epoch 224/300\n",
      "310/310 [==============================] - 0s 87us/step - loss: 61.7801\n",
      "Epoch 225/300\n",
      "310/310 [==============================] - 0s 87us/step - loss: 61.9966\n",
      "Epoch 226/300\n",
      "310/310 [==============================] - 0s 87us/step - loss: 63.3519\n",
      "Epoch 227/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 62.8967\n",
      "Epoch 228/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 62.2761\n",
      "Epoch 229/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 62.3209\n",
      "Epoch 230/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 62.8549\n",
      "Epoch 231/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 62.4788\n",
      "Epoch 232/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 62.1575\n",
      "Epoch 233/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 62.2528\n",
      "Epoch 234/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 62.0820\n",
      "Epoch 235/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 62.0214\n",
      "Epoch 236/300\n",
      "310/310 [==============================] - 0s 109us/step - loss: 64.7260\n",
      "Epoch 237/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 62.0995\n",
      "Epoch 238/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 61.8212\n",
      "Epoch 239/300\n",
      "310/310 [==============================] - 0s 87us/step - loss: 62.2807\n",
      "Epoch 240/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 61.1147\n",
      "Epoch 241/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 62.8845\n",
      "Epoch 242/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 61.3891\n",
      "Epoch 243/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 62.0019\n",
      "Epoch 244/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 61.7160\n",
      "Epoch 245/300\n",
      "310/310 [==============================] - 0s 96us/step - loss: 63.3429\n",
      "Epoch 246/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 61.7131\n",
      "Epoch 247/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 61.7493\n",
      "Epoch 248/300\n",
      "310/310 [==============================] - 0s 113us/step - loss: 61.7737\n",
      "Epoch 249/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 62.6422\n",
      "Epoch 250/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 61.3134\n",
      "Epoch 251/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 61.2633\n",
      "Epoch 252/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 61.9145\n",
      "Epoch 253/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 61.1911\n",
      "Epoch 254/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 62.6465\n",
      "Epoch 255/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 61.7835\n",
      "Epoch 256/300\n",
      "310/310 [==============================] - 0s 116us/step - loss: 63.5108\n",
      "Epoch 257/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 62.0991\n",
      "Epoch 258/300\n",
      "310/310 [==============================] - 0s 125us/step - loss: 61.8895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/300\n",
      "310/310 [==============================] - 0s 116us/step - loss: 62.0200\n",
      "Epoch 260/300\n",
      "310/310 [==============================] - 0s 90us/step - loss: 61.6876\n",
      "Epoch 261/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 62.1854\n",
      "Epoch 262/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 62.7473\n",
      "Epoch 263/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 61.6879\n",
      "Epoch 264/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 62.5549\n",
      "Epoch 265/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 61.4767\n",
      "Epoch 266/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 62.8054\n",
      "Epoch 267/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 61.4802\n",
      "Epoch 268/300\n",
      "310/310 [==============================] - 0s 77us/step - loss: 60.8848\n",
      "Epoch 269/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 61.1531\n",
      "Epoch 270/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 61.1855\n",
      "Epoch 271/300\n",
      "310/310 [==============================] - 0s 109us/step - loss: 61.1826\n",
      "Epoch 272/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 60.9815\n",
      "Epoch 273/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 61.2752\n",
      "Epoch 274/300\n",
      "310/310 [==============================] - 0s 109us/step - loss: 61.5847\n",
      "Epoch 275/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 61.4264\n",
      "Epoch 276/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 61.4583\n",
      "Epoch 277/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 61.4511\n",
      "Epoch 278/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 60.9721\n",
      "Epoch 279/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 62.5330\n",
      "Epoch 280/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 60.8709\n",
      "Epoch 281/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 62.2860\n",
      "Epoch 282/300\n",
      "310/310 [==============================] - 0s 109us/step - loss: 60.5190\n",
      "Epoch 283/300\n",
      "310/310 [==============================] - 0s 106us/step - loss: 60.8069\n",
      "Epoch 284/300\n",
      "310/310 [==============================] - 0s 93us/step - loss: 61.4466\n",
      "Epoch 285/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 61.3639\n",
      "Epoch 286/300\n",
      "310/310 [==============================] - 0s 87us/step - loss: 60.7696\n",
      "Epoch 287/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 60.6132\n",
      "Epoch 288/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 61.1281\n",
      "Epoch 289/300\n",
      "310/310 [==============================] - 0s 119us/step - loss: 60.7058\n",
      "Epoch 290/300\n",
      "310/310 [==============================] - 0s 113us/step - loss: 61.1830\n",
      "Epoch 291/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 61.4369\n",
      "Epoch 292/300\n",
      "310/310 [==============================] - 0s 109us/step - loss: 61.3584\n",
      "Epoch 293/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 62.1750\n",
      "Epoch 294/300\n",
      "310/310 [==============================] - 0s 113us/step - loss: 61.1595\n",
      "Epoch 295/300\n",
      "310/310 [==============================] - 0s 113us/step - loss: 61.5312\n",
      "Epoch 296/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 61.1592\n",
      "Epoch 297/300\n",
      "310/310 [==============================] - 0s 103us/step - loss: 60.5422\n",
      "Epoch 298/300\n",
      "310/310 [==============================] - 0s 97us/step - loss: 60.2328\n",
      "Epoch 299/300\n",
      "310/310 [==============================] - 0s 116us/step - loss: 60.5634\n",
      "Epoch 300/300\n",
      "310/310 [==============================] - 0s 100us/step - loss: 61.7888\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()  \n",
    "model.add(Dense(units = 8,use_bias = True,activation='relu',input_shape=(X_train.shape[1],) ))\n",
    "model.add(Dense(units = 16,use_bias = True,activation='relu'))\n",
    "model.add(Dense(units = 32,use_bias = True,activation='relu'))\n",
    "model.add(Dense(units = 16,use_bias = True,activation='relu'))\n",
    "model.add(Dense(units = 8,use_bias = True,activation='relu'))\n",
    "model.add(Dense(units = 1,activation='linear'))\n",
    "print(model.summary())\n",
    "model.compile(loss='mse',optimizer='nadam')\n",
    "history = model.fit(X_train, y_train,epochs=300,batch_size=68)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph for convergence loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAE for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.028694648742676"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pre = model.predict(X_train)\n",
    "mean_absolute_error(y_train, Y_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAE for testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.01095049564655"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pre = model.predict(X_test)\n",
    "mean_absolute_error(y_test, y_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.98639993000831"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, Y_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSE for testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.00070775992344"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, y_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R square for testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6904699862983015"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.r2_score(y_test,y_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSLE for testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05290539677562082"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_log_error(y_test,y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
